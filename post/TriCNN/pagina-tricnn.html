<!DOCTYPE html>
<html>
<title>Pato</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../../css/myStyle.css">
<style>
body {font-family: "Times New Roman", Georgia, Serif;}
h1, h2, h3, h4, h5, h6 {
  font-family: "Playfair Display";
  letter-spacing: 5px;
}
</style>
<body>

<!-- Navbar (sit on top) -->
<div class="w3-top">
  <div class="w3-bar w3-white w3-padding w3-card" style="letter-spacing:4px;">
    <a href="../../index.html#home" class="w3-bar-item w3-button">Patricio Rivera</a>
    <!-- Right-sided navbar links. Hide them on small screens -->
    <div class="w3-right w3-hide-small">
      <a href="../../index.html#top" class="w3-bar-item w3-button">About</a>
      <a href="../../index.html#publications" class="w3-bar-item w3-button">Publications</a>
      <a href="../../index.html#contact" class="w3-bar-item w3-button">Contact</a>
    </div>
  </div>
</div>

<!-- Header -->
<header class="w3-display-container w3-content w3-wide" style="max-width:1600px;min-width:500px;max-height:800px;" id="home">
  <br><br><br>
  <h1 class="w3-center w3-padding-large w3-margin">Trilateral convolutional neural network for 3D shape reconstruction of objects from a single depth view</h1>
</header>

<!-- Page content -->
<div class="w3-content" style="max-width:1100px">

  <!-- Abstract Section -->
  <div class="w3-row w3-padding-64" id="about">
    <div class="w3-col s12 w3-center w3-padding-large">
      <img class="w3-image w3-round" src="imagen-general-tricnn.jpg" alt="General Figure Paper" width="1600" height="800">
      <h1>Abstract</h1><br>
      <p class="w3-large">
          n this study, the authors propose a novel three-dimensional (3D) convolutional neural network for shape 
          reconstruction via a trilateral convolutional neural network (Tri-CNN) from a single depth view. 
          The proposed approach produces a 3D voxel representation of an object, derived from a partial object surface 
          in a single depth image. The proposed Tri-CNN combines three dilated convolutions in 3D to expand the convolutional 
          receptive field more efficiently to learn shape reconstructions. To evaluate the proposed Tri-CNN in terms of 
          reconstruction performance, the publicly available ShapeNet and Big Data for Grasp Planning data sets are utilised.
          The reconstruction performance was evaluated against four conventional deep learning approaches: namely, fully connected
          convolutional neural network, baseline CNN, autoencoder CNN, and a generative adversarial reconstruction network. The 
          proposed experimental results show that Tri-CNN produces superior reconstruction results in terms of intersection 
          over union values and Brier scores with significantly less number of model parameters and memory.</p>
    </div>
  </div>

  <div class="w3-row w3-padding-large w3-center">
    <span class='w3-col s5'></span>
    <span class='w3-col s2'><a href="../../index.html" class="w3-button">Go Back</a></span>
  </div>

  <hr>
<!-- End page content -->
</div>

<!-- Footer -->
<footer class="w3-right-align w3-light-grey w3-padding-small">
  <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-text-green">w3.css</a></p>
</footer>

</body>
</html>


 <!-- 
    ***"A single wearable IMU-based Human Hand Activity Recognition via Deep Autoencoder and Recurrent Neural Networks"***<br/>
    **P. Rivera**, E. Valarezo, S.M. Lee, K.M. Byun, M.H. Cho, S.Y. Lee, T.-S. Kim <br/>
    [paper](http://www.ijpmbs.com/uploadfile/2017/1227/20171227050020234.pdf)<br/>
    ***"Smoking Activity Recognition Using a Single Wrist IMU and Deep Learning Light"***<br/>
    E. Valarezo, **P. Rivera**, S. Lee, K. Buyn, T.-S. Kim <br/>
    [paper](https://dl.acm.org/citation.cfm?id=3193028)<br/>
    * **2017**
    ***"Recognition of Human Hand Activities Based on a Single Wrist IMU Using Recurrent Neural Networks"***<br/>
    **Patricio Rivera**, Edwin Valarezo, Mun-Taek Choi, Tae-Seong Kim<br/>
    [paper](http://www.ijpmbs.com/index.php?m=content&c=index&a=show&catid=144&id=252)<br/>
    ***"Human Activity Recognition Using Single Wrist IMU Sensor via Deep Learning Convolutional and Recurrent Neural Nets"***<br/>
    E. Valarezo,  **P. Rivera**, J. M. Park, G. Gi, T. Y. Kim, M. A. Al-antari, M. Al-masani, T. S. Kim.<br/>
    [paper](http://www.tafpublications.com/gip_content/paper/JITDETS-1.1.1.pdf)<br/>
    ***"Detection and Classification of the Breast Abnormalities in Digital Mammograms via Regional Convolutional Neural Network"***<br/>
    M. A. Al-masani, M. A. Al-antari, J. M. Park, G. Gi, T. Y. Kim, **P. Rivera**, E. Valarezo, S.-M. Han, T.-S. Kim.<br/>
    [paper](https://ieeexplore.ieee.org/document/8037053)<br/>
    ***"Non-Local Means Filter Denoising for DEXA Image"***<br/>
    M. A. Al- antari, M. A. Al-masni, M. Metwally, D. Hussain, E. Valarezo, **P. Rivera**, G. Gi, J. M. Park, T. Y. Kim, S.-J. Park, J.-S. Shin, S.-M. Han, T.-S. Kim.<br/>
    [paper](https://ieeexplore.ieee.org/document/8036889/)<br/>
    * **2016**
    ***"Analysis of blood pressure signal in patients with different ventricular ejection fraction using linear and non-linear methods"*** <br/>
    Arcentales A, **Rivera P**, Caminal P, Voss A, Bayes-Genis A, Giraldo BF.<br/>
    [paper](https://ieeexplore.ieee.org/document/7591287/)<br/> -->

